# -*- coding: utf-8 -*-
"""jcompFDAheartynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ixvn5jaMiq8OIAcvB9l_FTnRzmGCc6l4

# Installing Packages & Attaching Library
"""

library(tidyverse)

install.packages("gtools", repos="https://cran.rstudio.com/")
install.packages("gmodels", repos="https://cran.rstudio.com/")

install.packages("caret", repos="https://cran.rstudio.com/")

install.packages("rmdformats", repos="https://cran.rstudio.com/")

library(dplyr)
library(gtools)
library(gmodels)
library(ggplot2)
library(class)
library(tidyr)
library(lattice)
library(rmdformats)
library(caret)

"""# Explore Dataset


"""

#Data Import
heart <- read.csv("heart.csv")
dim(heart)

# Overview of Data
glimpse(heart)

head(heart, 3)

"""# Data Wrangling"""

heart <- heart %>%
  #mutate_if(is.integer, as.factor) %>%
  mutate(cp = as.factor(cp),
         restecg = as.factor(restecg),
         slope = as.factor(slope),
         ca = as.factor(ca),
         thal = as.factor(thal),
         sex = factor(sex, levels = c(0,1), labels = c("female", "male")),
         fbs = factor(fbs, levels = c(0,1), labels = c("False", "True")),
         exang = factor(exang, levels = c(0,1), labels = c("No", "Yes")),
         target = factor(target, levels = c(0,1), labels = c("Health", "Not Health")))

glimpse(heart)

colSums(is.na(heart))

"""# Data Pre-Processing"""

prop.table(table(heart$target))

table(heart$target)

"""We can see that our proportion is balance enough, and we do not need to balancing the class by using down sample or up sample method.

# Data Visualisation
"""

ggplot(heart, aes(x=heart$target, fill=heart$target))+
   geom_bar()+
   xlab("Heart Disease")+
   ylab("count")+
   ggtitle("Presence & Absence of Heart Disease")+
   scale_fill_discrete (name= 'Heart Disease', labels=c("Absence", "Presence"))

# count the frequency of the values of age
heart  %>%
     group_by (age)  %>%
     count()  %>%
     filter(n>10)  %>%
     ggplot()+
     geom_col(aes(age, n), fill ='green')+ 
     ggtitle("Age Analysis")+
     xlab("Age")+
     ylab("Agecount")

# comapre blood pressure across the chest pain

heart %>%
  ggplot (aes (x=sex, y=trestbps))+
  geom_boxplot (fill ='purple')+
  xlab('sex')+
  ylab('BP')+
  facet_grid(~cp)

#comapre cholestrol across the chest pain

heart %>%
  ggplot (aes (x=sex, y=chol))+
  geom_boxplot (fill ='orange')+
  xlab('sex')+
  ylab('chol')+
  facet_grid(~cp)

"""# Cross Validation

Next step of our analysis will be splitting our data into train and test data. We will use our train data to train our model and use our test data to validate our model when overcoming the unseen data.
"""

set.seed(100)
index <- sample(nrow(heart), nrow(heart)*0.7)

# Data train
train_heart <- heart[index,]

# Data test
test_heart <- heart[-index,]

"""Next, we will check our train data proportion whether the proportion is balance enough to train our model, this need to be done so we can minimize the risk that our models are overfit."""

prop.table(table(train_heart$target))

"""# Modelling

We will create a model based on our train data. we will use several variables that may have a significant effect toward our target variable like sex, cp, fbs, and thal.

Then we will also use the stepwise method to see if we can get a better model than our previous one
"""

# Create a model
model1 <- glm(formula = target ~ sex + cp +  fbs + thal, family = "binomial", data = train_heart)

# Model summary
summary(model1)

"""as we can see, there are only several variables that are significant toward our model. As we have not try other variable that may have been affected our target variable, we will try to use stepwise method to create a better model than our previous one."""

# Create a model without predictor
model_none <- glm(target ~ 1, family = "binomial", data = train_heart)

# Create a model with all predictor
model_all <- glm(target ~ ., family = "binomial", data = train_heart)

# Stepwise regression backward
model_back <- step(object = model_all, direction = "backward", trace = F)

# Stepwise regression forward
model_forw <- step(object = model_all, scope = list(lower = model_none, upper = model_all), direction = "forward", trace = F)

# Stepwise regression both
model_both <- step(object = model_all, scope = list(lower = model_none, upper = model_all), direction = "both", trace = F)

"""Next we will see our model summary in each of the model that we have been created before.

We will see it based on:

AIC, amount of information lost in the model, lower AIC indicate a good quality of a model.
Residual Deviance, Error of the model when the model have a predictor, lower Residual Deviance means we have a better model
"""

# Model Summary

# Backward

summary(model_back)

# Forward

summary(model_forw)

# Both

summary(model_both)

"""Based on the result, we can see that our model_back and model_both have a similar value of AIC & Residual Deviance. Both of those model have the AIC value 161.71 and the Residual deviance value 127.71. while our model_forw have the AIC value 168.15 and the Residual deviance value 122.15.

Although our model_forw have a better Residual Deviance than other model, the number of variables that significant towards the our target variables are not as much as the other two models. Therefore, we will not choose model_forw and proceed to choose either the model_back or model_both.

In this case we will choose model_both for our further analysis.

# Prediction
"""

test_heart$prediction <-  predict(model_both, type = "response", newdata = test_heart)

# Create Plot

test_heart %>%
  ggplot(aes(x=prediction)) +
  geom_density() +
  labs(title = "Probabilities Distribution of Prediction Data") +
  theme_minimal()

pred <- predict(model_both, type = "response", newdata = test_heart)

result_pred <- ifelse(pred >= 0.5, "Not Health", "Health")

# Put our result prediction into our test data

test_heart$prediction <- result_pred

"""Here are the overview comparison between our prediction data and the target variable of our test data"""

test_heart %>%
  select(target, prediction) %>%
  head(5)

"""# Model Evalution

LOGISTIC REGRESSION
"""

conf_mat <- confusionMatrix(as.factor(result_pred), reference = test_heart$target, positive = "Not Health")

conf_mat

recall <- round(46/(46+4),3)
specificity <- round(30/(30+11),3)
precision <- round(46/(46+11),3)
accuracy <- round((46+30)/(46+30+11+4),3)

matrix <- cbind.data.frame(accuracy, recall, specificity, precision)

matrix

"""Based on the matrix summary, we can see that the ability of our model to predict our target variable are 83.5%. from entire of our prediction data. Our model ability to correctly predicted the Not Health person is 92%, while it ability to correctly predicted the Health person is 73.2%. Furthermore, from all of Not Health prediction our model able to predict it correctly 80.7%

Decision Tree
"""

install.packages("rpart", repos="https://cran.rstudio.com/")
install.packages("rpart.plot", repos="https://cran.rstudio.com/")

library(rpart)#for rpart decision tree
library(rpart.plot)#for visualising the tree
model.tree<-rpart(target~.,data = train_heart)
rpart.plot(model.tree)

confusionMatrix(as.factor(predict(model.tree,newdata = test_heart, type = 'class')),test_heart$target)

"""Random Forest"""

install.packages("randomForest", repos="https://cran.rstudio.com/")
library(randomForest)

model.rf<-randomForest(target~., train_heart, importance = T, ntree=500)

print('Random Forest Accuracy')
confusionMatrix(as.factor(predict(model.rf,newdata = test_heart, type = 'class')),test_heart$target)

"""Single Layer Nueral Network"""

install.packages("nnet", repos="https://cran.rstudio.com/")
install.packages("NeuralNetTools", repos="https://cran.rstudio.com/")

library(nnet)#for neural netwrok model
library(NeuralNetTools)#for neural network plot
model.nn<-nnet(target~.,data = train_heart, size = 5 , maxit = 1000)
plotnet(model.nn)

print('Neural Network Accuracy')
confusionMatrix(as.factor(predict(model.nn,newdata = test_heart, type = 'class')),test_heart$target)



"""Support Vector Machine 

"""

data2<-read.csv("heart.csv")

install.packages("e1071", repos="https://cran.rstudio.com/")
install.packages("pkList", repos="https://cran.rstudio.com/")

library("e1071")

#We’ll be using the training set specifically for our model building and the testing set for evaluating the model:
intrain <- createDataPartition(y = data2$fbs, p= 0.7, list = FALSE)
training <- data2[intrain,]
testing <- data2[-intrain,]

dim(training); 
dim(testing);

anyNA(data2)

summary(data2)

training[["fbs"]] = factor(training[["fbs"]])

##Before we train our model, we’ll first implement the trainControl() method. This will control all the computational overheads so that we can use the train() function provided by the caret package. The training method will train our data on different algorithms.

#First, let’s focus on the traincontrol() method:

trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

svm_Linear <- svm(fbs ~ ., data=training)
summary(svm_Linear)

test_pred <- predict(svm_Linear, newdata = testing)
test_pred

confusionMatrix(table(test_pred, testing$fbs))

"""K Nearest Neighbour  - Data Wrangling

"""

# Create dummy variable

dummy <- dummyVars("~target + sex +cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal", data = heart)

# Create new data frame

dummy <- data.frame(predict(dummy, newdata = heart))

# Check our data frame structure

str(dummy)

dummy$target.Health <- NULL
dummy$sex.female <- NULL
dummy$fbs.False <- NULL
dummy$exang.No <- NULL

head(dummy, 3)

"""Cross Validation: K - Nearest Method"""

set.seed(100)

# Predictor

train_x <- dummy[index, -1]
test_x <- dummy[-index, -1]

# Target

train_y <- dummy[index, 1]
test_y <- dummy[-index, 1]

"""CHoose K"""

sqrt(nrow(train_x))

"""Scaling"""

train_x <- scale(x = train_x)
test_x <- scale(x = test_x, center = attr(train_x, "scaled:center"), scale = attr(train_x, "scaled:scale"))

"""Prediction"""

pred_knn <- knn(train = train_x, test = test_x, cl = train_y, k = 14)

pred_knn <- pred_knn %>%
  as.data.frame() %>%
  mutate(pred_knn = factor(pred_knn, levels = c(0,1), labels = c("Health", "Not Health"))) %>%
  select(pred_knn)

test_y <- test_y %>%
  as.data.frame() %>%
  mutate(target = factor(test_y, levels = c(0,1), labels = c("Health", "Not Health"))) %>%
  select(target)

"""Confusion matrix of KNN prediction"""

conf_mat_knn <- confusionMatrix(pred_knn$pred_knn, reference = test_y$target, positive = "Not Health")

conf_mat_knn

recall_knn <- round(48/(48+2),3)
specificity_knn <- round(29/(29+12),3)
precision_knn <- round(48/(48+12),3)
accuracy_knn <- round((48+29)/(48+29+12+2),3)

matrix_knn <- cbind.data.frame(accuracy_knn, recall_knn, specificity_knn, precision_knn)

matrix_knn